"""
    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs
    http://arxiv.org/abs/1711.09869
    2017 Loic Landrieu, Martin Simonovsky
"""
from __future__ import division
from __future__ import print_function
from builtins import range

import time
import random
import numpy as np
import json
import os
import sys
import math
import argparse
import ast
from tqdm import tqdm
import logging
from collections import defaultdict
import h5py

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import MultiStepLR
from torch.autograd import Variable
import torchnet as tnt

DIR_PATH = os.path.dirname(os.path.realpath(__file__))
sys.path.insert(0, os.path.join(DIR_PATH,'..'))

from learning import spg
from learning import graphnet
from learning import pointnet
from learning import metrics

#Create related functions
def create_model(args, dbinfo):
    """ Creates model """
    model = nn.Module()

    nfeat = args.ptn_widths[1][-1]   #nfeat=32
    model.ecc = graphnet.GraphNetwork(args.model_config, nfeat, [dbinfo['edge_feats']] + args.fnet_widths, args.fnet_orthoinit, args.fnet_llbias,args.fnet_bnidx, args.edge_mem_limit)
    model.ptn = pointnet.PointNet(args.ptn_widths[0], args.ptn_widths[1], args.ptn_widths_stn[0], args.ptn_widths_stn[1], dbinfo['node_feats'], args.ptn_nfeat_stn, prelast_do=args.ptn_prelast_do)

    print('Total number of parameters: {}'.format(sum([p.numel() for p in model.parameters()])))
    #print(model)
    model.cuda()
    return model

def create_optimizer(args, model):    #default:optim='adam'
    # if args.optim=='sgd':
    #     return optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd)
    # elif args.optim=='adam':
    #     return optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)
    return optim.Adam(model.parameters(),lr=args.lr,weight_decy=args.wd)

def set_seed(seed, cuda=True):
    """ Sets seeds in all frameworks"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)

def filter_valid(output, target, other=None):
    """ Removes predictions for nodes without ground truth,删除对没有地面真理的节点的预测 """
    idx = target!=-100
    # if other is not None:
    #     return output[idx,:], target[idx], other[idx,...]
    return output[idx,:], target[idx]

def meter_value(meter):
    return meter.value()[0] if meter.n>0 else 0


def main():
    parser = argparse.ArgumentParser(description='Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs')

    #parameters
    """parser.add_argument()"""

    args = parser.parse_args()
    args.start_epoch = 0
    args.lr_steps = ast.literal_eval(args.lr_steps)
    args.fnet_widths = ast.literal_eval(args.fnet_widths)
    args.ptn_widths = ast.literal_eval(args.ptn_widths)
    args.ptn_widths_stn = ast.literal_eval(args.ptn_widths_stn)


#Don't their means.
    print('Will save to ' + args.odir)
    if not os.path.exists(args.odir):
        os.makedirs(args.odir)
    with open(os.path.join(args.odir, 'cmdline.txt'), 'w') as f:
        f.write(" ".join(["'"+a+"'" if (len(a)==0 or a[0]!='-') else a for a in sys.argv]))

    set_seed(args.seed, args.cuda)
    logging.getLogger().setLevel(logging.INFO)  #set to logging.DEBUG to allow for more prints
    if (args.dataset=='sema3d' and args.db_test_name.startswith('test')) or (args.dataset.startswith('s3dis_02') and args.cvfold==2):
        # needed in pytorch 0.2 for super-large graphs with batchnorm in fnet  (https://github.com/pytorch/pytorch/pull/2919)
        torch.backends.cudnn.enabled = False
    ##################

#Decide on the dataset
    import sema3d_dataset                           #主要的数据
    dbinfo = sema3d_dataset.get_info(args)          #返回sema3d_dataset的相关信息
    create_dataset = sema3d_dataset.get_datasets    #获取训练、测试和评估数据
    train_dataset, test_dataset, valid_dataset, scaler = create_dataset(args)

#Create model and optimizer
    model = create_model(args, dbinfo)  # 添加图卷积和Pointnet
    optimizer = create_optimizer(args, model)  # 添加优化器  optimizer='Adam'
    stats = []

    print('Train dataset: %i elements - Test dataset: %i elements - Validation dataset: %i elements' % (len(train_dataset),len(test_dataset),len(valid_dataset)))
    ptnCloudEmbedder = pointnet.CloudEmbedder(args)   #CloudEmbedder()没看懂.
    scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_decay, last_epoch=args.start_epoch-1)   #查MultiStepLR
    #MultiStepLR:调整学习率

#Training layer
    def train():
        """ Trains for one epoch """
        model.train()

        loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=spg.eccpc_collate, num_workers=args.nworkers, shuffle=True, drop_last=True)
        if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=65)

        loss_meter = tnt.meter.AverageValueMeter()
        acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)
        confusion_matrix = metrics.ConfusionMatrix(dbinfo['classes'])
        t0 = time.time()

        # iterate over dataset in batches(批量迭代数据集)
        for bidx, (targets, GIs, clouds_data) in enumerate(loader):
            t_loader = 1000*(time.time()-t0)

            model.ecc.set_info(GIs, args.cuda)
            label_mode_cpu, label_vec_cpu, segm_size_cpu = targets[:,0], targets[:,2:], targets[:,1:].sum(1)
            # if args.cuda:
            #     label_mode, label_vec, segm_size = label_mode_cpu.cuda(), label_vec_cpu.float().cuda(), segm_size_cpu.float().cuda()
            # else:
            #     label_mode, label_vec, segm_size = label_mode_cpu, label_vec_cpu.float(), segm_size_cpu.float()
            label_mode,label_vec,segm_size=label_mode_cpu.cuda(), label_vec_cpu.float().cuda(), segm_size_cpu.float().cuda()

            optimizer.zero_grad()
            t0 = time.time()

            embeddings = ptnCloudEmbedder.run(model, *clouds_data)
            outputs = model.ecc(embeddings)

            loss = nn.functional.cross_entropy(outputs, Variable(label_mode), weight=dbinfo["class_weights"])

            loss.backward()
            ptnCloudEmbedder.bw_hook()

            if args.grad_clip>0:   #grad_clip:default=1
                for p in model.parameters():
                    p.grad.data.clamp_(-args.grad_clip, args.grad_clip)
            optimizer.step()

            t_trainer = 1000*(time.time()-t0)
            #loss_meter.add(loss.data[0]) # pytorch 0.3
            loss_meter.add(loss.item()) # pytorch 0.4

            o_cpu, t_cpu, tvec_cpu = filter_valid(outputs.data.cpu().numpy(), label_mode_cpu.numpy(), label_vec_cpu.numpy())
            acc_meter.add(o_cpu, t_cpu)
            confusion_matrix.count_predicted_batch(tvec_cpu, np.argmax(o_cpu,1))

            logging.debug('Batch loss %f, Loader time %f ms, Trainer time %f ms.', loss.data.item(), t_loader, t_trainer)
            t0 = time.time()

        return acc_meter.value()[0], loss_meter.value()[0], confusion_matrix.get_overall_accuracy(), confusion_matrix.get_average_intersection_union()

#Evaluation layer
    def eval(is_valid=False):
        """ Evaluated model on test set """
        model.eval()

        # if is_valid:  # validation验证
        #     loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, collate_fn=spg.eccpc_collate,
        #                                          num_workers=args.nworkers)
        # else:  # evaluation评估
        #     loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, collate_fn=spg.eccpc_collate,
        #                                          num_workers=args.nworkers)
        loader = torch.utils.data.DataLoader(test_dataset,batch_size=1,collate_fn=spg.eccpc_collate)

        if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=65)

        acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)
        loss_meter = tnt.meter.AverageValueMeter()
        confusion_matrix = metrics.ConfusionMatrix(dbinfo['classes'])

        # iterate over dataset in batches  批量迭代数据集
        for bidx, (targets, GIs, clouds_data) in enumerate(loader):
            model.ecc.set_info(GIs, args.cuda)
            label_mode_cpu, label_vec_cpu, segm_size_cpu = targets[:, 0], targets[:, 2:], targets[:, 1:].sum(1).float()
            if args.cuda:
                label_mode, label_vec, segm_size = label_mode_cpu.cuda(), label_vec_cpu.float().cuda(), segm_size_cpu.float().cuda()
            else:
                label_mode, label_vec, segm_size = label_mode_cpu, label_vec_cpu.float(), segm_size_cpu.float()

            embeddings = ptnCloudEmbedder.run(model, *clouds_data)
            outputs = model.ecc(embeddings)

            loss = nn.functional.cross_entropy(outputs, Variable(label_mode), weight=dbinfo["class_weights"])
            loss_meter.add(loss.item())

            o_cpu, t_cpu, tvec_cpu = filter_valid(outputs.data.cpu().numpy(), label_mode_cpu.numpy(),
                                                  label_vec_cpu.numpy())
            if t_cpu.size > 0:
                acc_meter.add(o_cpu, t_cpu)
                confusion_matrix.count_predicted_batch(tvec_cpu, np.argmax(o_cpu, 1))

        return meter_value(acc_meter), loss_meter.value()[0], confusion_matrix.get_overall_accuracy(), \
               confusion_matrix.get_average_intersection_union(), confusion_matrix.get_mean_class_accuracy()

#Final evaluation layer
    def eval_final():
        """ Evaluated model on test set in an extended way: computes estimates over multiple samples of point clouds and stores predictions """
        #以扩展方式对测试集进行评估的模型：计算多个点云样本的估计并存储预测
        model.eval()

        acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)
        confusion_matrix = metrics.ConfusionMatrix(dbinfo['classes'])
        collected, predictions = defaultdict(list), {}

        # collect predictions over multiple sampling seeds 收集多个采样种子的预测
        for ss in range(args.test_multisamp_n):    #test_multisamp_n: default=10 help:使用不同种子运行时获得的平均对数
            test_dataset_ss = create_dataset(args, ss)[1]
            loader = torch.utils.data.DataLoader(test_dataset_ss, batch_size=1, collate_fn=spg.eccpc_collate,
                                                 num_workers=args.nworkers)
            if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=65)

            # iterate over dataset in batches   批量迭代数据集
            for bidx, (targets, GIs, clouds_data) in enumerate(loader):
                model.ecc.set_info(GIs, args.cuda)
                label_mode_cpu, label_vec_cpu, segm_size_cpu = targets[:, 0], targets[:, 2:], targets[:, 1:].sum(
                    1).float()

                embeddings = ptnCloudEmbedder.run(model, *clouds_data)
                outputs = model.ecc(embeddings)

                fname = clouds_data[0][0][:clouds_data[0][0].rfind('.')]
                collected[fname].append((outputs.data.cpu().numpy(), label_mode_cpu.numpy(), label_vec_cpu.numpy()))

        # aggregate predictions (mean) 汇总预测（平均值）
        for fname, lst in collected.items():
            o_cpu, t_cpu, tvec_cpu = list(zip(*lst))
            # if args.test_multisamp_n > 1:
            #     o_cpu = np.mean(np.stack(o_cpu, 0), 0)
            # else:
            #     o_cpu = o_cpu[0]
            o_cpu = np.mean(np.stack(o_cpu,0),0)
            t_cpu, tvec_cpu = t_cpu[0], tvec_cpu[0]
            predictions[fname] = np.argmax(o_cpu, 1)
            o_cpu, t_cpu, tvec_cpu = filter_valid(o_cpu, t_cpu, tvec_cpu)
            if t_cpu.size > 0:
                acc_meter.add(o_cpu, t_cpu)
                confusion_matrix.count_predicted_batch(tvec_cpu, np.argmax(o_cpu, 1))

        per_class_iou = {}
        perclsiou = confusion_matrix.get_intersection_union_per_class()
        for c, name in dbinfo['inv_class_map'].items():
            per_class_iou[name] = perclsiou[c]

        return meter_value(
            acc_meter), confusion_matrix.get_overall_accuracy(), confusion_matrix.get_average_intersection_union(), per_class_iou, predictions, confusion_matrix.get_mean_class_accuracy(), confusion_matrix.confusion_matrix

    ############
    # Training loop 循环训练
    try:
        best_iou = stats[-1]['best_iou']
    except:
        best_iou = 0
    TRAIN_COLOR = '\033[0m'
    VAL_COLOR = '\033[0;94m'
    TEST_COLOR = '\033[0;93m'
    BEST_COLOR = '\033[0;92m'
    epoch = args.start_epoch

    for epoch in range(args.start_epoch, args.epochs):
        print('Epoch {}/{} ({}):'.format(epoch, args.epochs, args.odir))
        scheduler.step()

        acc, loss, oacc, avg_iou = train()

        print(TRAIN_COLOR + '-> Train Loss: %1.4f   Train accuracy: %3.2f%%' % (loss, acc))

        new_best_model = False
        # if args.use_val_set:   #args.use_val_set: default=0
        #     acc_val, loss_val, oacc_val, avg_iou_val, avg_acc_val = eval(True)
        #     print(
        #         VAL_COLOR + '-> Val Loss: %1.4f  Val accuracy: %3.2f%%  Val oAcc: %3.2f%%  Val IoU: %3.2f%%  best ioU: %3.2f%%' % \
        #         (loss_val, acc_val, 100 * oacc_val, 100 * avg_iou_val, 100 * max(best_iou, avg_iou_val)) + TRAIN_COLOR)
        #     if avg_iou_val > best_iou:  # best score yet on the validation set
        #         print(BEST_COLOR + '-> New best model achieved!' + TRAIN_COLOR)
        #         best_iou = avg_iou_val
        #         new_best_model = True
        #         torch.save({'epoch': epoch + 1, 'args': args, 'state_dict': model.state_dict(),
        #                     'optimizer': optimizer.state_dict()},
        #                    os.path.join(args.odir, 'model.pth.tar'))
        # elif epoch % args.save_nth_epoch == 0 or epoch == args.epochs - 1:   #args.save_nth_epoch:default=1 #args.epoch:default=10
        #     torch.save({'epoch': epoch + 1, 'args': args, 'state_dict': model.state_dict(),
        #                 'optimizer': optimizer.state_dict()},
        #                os.path.join(args.odir, 'model.pth.tar'))
        torch.save({'epoch':epoch+1,'args':args,'state_dict':model.state_dict(),
                    'optimizer':optimizer.state_dict()},
                     os.path.join(args.odir, 'model.pth.tar'))

        # test every test_nth_epochs or test after each enw model (but skip the first 5 for efficiency)
        # 测试每个test_nth_epochs或在每个enw模型之后进行测试（但跳过前5个以提高效率）

        # if (not (args.use_val_set) and (epoch + 1) % args.test_nth_epoch == 0) \
        #         or (args.use_val_set and new_best_model and epoch > 5): #args.use_val_set:default=0; args.test_nth_epoch:default=1
        #     acc_test, loss_test, oacc_test, avg_iou_test, avg_acc_test = eval(False)
        #     print(TEST_COLOR + '-> Test Loss: %1.4f  Test accuracy: %3.2f%%  Test oAcc: %3.2f%%  Test avgIoU: %3.2f%%' % \
        #
        # else:
        #     acc_test, loss_test, oacc_test, avg_iou_test, avg_acc_test = 0, 0, 0, 0, 0
        acc_test,loss_test,oacc_test,avg_iou_test,avg_acc_test=eval(False)
        print(TEST_COLOR+'-> Test Loss: %1.4f Test accuracy:%3.2f%% Test oAcc: %3.2f%% Test avgIoU: %3.2f%%' %(loss_test, acc_test, 100 * oacc_test, 100 * avg_iou_test) + TRAIN_COLOR)

        stats.append({'epoch': epoch, 'acc': acc, 'loss': loss, 'oacc': oacc, 'avg_iou': avg_iou, 'acc_test': acc_test,
                      'oacc_test': oacc_test, 'avg_iou_test': avg_iou_test, 'avg_acc_test': avg_acc_test,
                      'best_iou': best_iou})

        # if epoch % args.save_nth_epoch == 0 or epoch == args.epochs - 1:  #args.save_nth_epochs:default=1; args.epoch:default=10
        #     with open(os.path.join(args.odir, 'trainlog.json'), 'w') as outfile:
        #         json.dump(stats, outfile, indent=4)
        #     torch.save({'epoch': epoch + 1, 'args': args, 'state_dict': model.state_dict(),
        #                 'optimizer': optimizer.state_dict(), 'scaler': scaler},
        #                os.path.join(args.odir, 'model.pth.tar'))
        with open(os.path.join(args.odir, 'trainlog.json'), 'w') as outfile:json.dump(stats, outfile, indent=4)
        torch.save({'epoch': epoch + 1, 'args': args, 'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(), 'scaler': scaler},os.path.join(args.odir, 'model.pth.tar'))

        if math.isnan(loss): break

    if len(stats) > 0:
        with open(os.path.join(args.odir, 'trainlog.json'), 'w') as outfile:
            json.dump(stats, outfile, indent=4)

    # if args.use_val_set:  #args.use_val_set:default=0;
    #     args.resume = args.odir + '/model.pth.tar'
    #     model, optimizer, stats = resume(args, dbinfo)
    #     torch.save(
    #         {'epoch': epoch + 1, 'args': args, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()},
    #         os.path.join(args.odir, 'model.pth.tar'))

    # Final evaluation
    # if args.test_multisamp_n > 0 and args.db_test_name == 'test':  #args.test_multisamp_n:default=10;args.db_test_name:default='test'
    #     acc_test, oacc_test, avg_iou_test, per_class_iou_test, predictions_test, avg_acc_test, confusion_matrix = eval_final()
    #     print('-> Multisample {}: Test accuracy: {}, \tTest oAcc: {}, \tTest avgIoU: {}, \tTest mAcc: {}'.format(
    #         args.test_multisamp_n, acc_test, oacc_test, avg_iou_test, avg_acc_test))
    #     with h5py.File(os.path.join(args.odir, 'predictions_' + args.db_test_name + '.h5'), 'w') as hf:
    #         for fname, o_cpu in predictions_test.items():
    #             hf.create_dataset(name=fname, data=o_cpu)  # (0-based classes)
    #     with open(os.path.join(args.odir, 'scores_' + args.db_test_name + '.json'), 'w') as outfile:
    #         json.dump([{'epoch': args.start_epoch, 'acc_test': acc_test, 'oacc_test': oacc_test,
    #                     'avg_iou_test': avg_iou_test, 'per_class_iou_test': per_class_iou_test,
    #                     'avg_acc_test': avg_acc_test}], outfile)
    #     np.save(os.path.join(args.odir, 'pointwise_cm.npy'), confusion_matrix)

    acc_test, oacc_test, avg_iou_test, per_class_iou_test, predictions_test, avg_acc_test, confusion_matrix = eval_final()
    print('-> Multisample {}: Test accuracy: {}, \tTest oAcc: {}, \tTest avgIoU: {}, \tTest mAcc: {}'.format(args.test_multisamp_n, acc_test, oacc_test, avg_iou_test, avg_acc_test))
    with h5py.File(os.path.join(args.odir, 'predictions_' + args.db_test_name + '.h5'), 'w') as hf:
        for fname, o_cpu in predictions_test.items():
                hf.create_dataset(name=fname, data=o_cpu)  # (0-based classes)
    with open(os.path.join(args.odir, 'scores_' + args.db_test_name + '.json'), 'w') as outfile:
        json.dump([{'epoch': args.start_epoch,
                    'acc_test': acc_test,
                    'oacc_test': oacc_test,
                    'avg_iou_test': avg_iou_test,
                    'per_class_iou_test': per_class_iou_test,
                    'avg_acc_test': avg_acc_test}], outfile)
    np.save(os.path.join(args.odir, 'pointwise_cm.npy'), confusion_matrix)


#Resume layer
def resume(args, dbinfo):
    """ Loads model and optimizer state from a previous checkpoint. 从先前的检查点加载模型和优化器状态。"""
    print("=> loading checkpoint '{}'".format(args.resume))
    checkpoint = torch.load(args.resume)   #args.resume:default=''  加载先前保存的模型。

    checkpoint['args'].model_config = args.model_config  # to ensure compatibility with previous arguments convention
    # this should be removed once new models are uploaded
    #确保与以前的参数约定兼容,新模型上传后，应将其删除  #args.model_config:default='gru_10,f_8'
    model = create_model(checkpoint['args'], dbinfo)  # use original arguments, architecture can't change  使用原始参数，架构无法更改
    optimizer = create_optimizer(args, model)

    # model.load_state_dict(checkpoint['state_dict'])
    # to ensure compatbility of previous trained models with new InstanceNormD behavior comment line below and uncomment line above if not using our trained  models
    model.load_state_dict({k: checkpoint['state_dict'][k] for k in checkpoint['state_dict'] if
                           k not in ['ecc.0._cell.inh.running_mean', 'ecc.0._cell.inh.running_var',
                                     'ecc.0._cell.ini.running_mean', 'ecc.0._cell.ini.running_var']})

    if 'optimizer' in checkpoint: optimizer.load_state_dict(checkpoint['optimizer'])
    for group in optimizer.param_groups: group['initial_lr'] = args.lr  #args.lr:fault=1e-3 help="初始学习率"
    args.start_epoch = checkpoint['epoch']
    try:
        stats = json.loads(open(os.path.join(os.path.dirname(args.resume), 'trainlog.json')).read())
    except:
        stats = []
    return model, optimizer, stats



if __name__ == "__main__":
    main()
